{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor实际上是指针类型，指向TensorImpl.\n",
    "\n",
    "伪代码如下:\n",
    "```\n",
    "class Tensor {\n",
    "    protected:\n",
    "        shared_ptr<TensorImpl> impl_;\n",
    "    public:\n",
    "    IntList sizes() const {\n",
    "        return impl_->sizes();\n",
    "    }\n",
    "    int64_t dim() const {\n",
    "        return impl_->dim();\n",
    "    }\n",
    "    IntList strides() const {\n",
    "        return impl_->strides();\n",
    "    }\n",
    "    int64_t storage_offset() const {\n",
    "        return impl_->storage_offset();\n",
    "    }\n",
    "    bool is_contiguous() const {\n",
    "        return impl_->is_contiguous();\n",
    "    }\n",
    "    Type & type() const {\n",
    "        return legacyTensorType(*impl_);\n",
    "    }\n",
    "    const Storage& storage() const {\n",
    "        return impl_->storage();\n",
    "    }\n",
    "    \n",
    "    template<typename T> T * data() const;\n",
    "    Tensor& grad() {\n",
    "        return impl_->grad();\n",
    "    }\n",
    "    ...\n",
    "};\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor源码在aten/src/ATen目录下."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "继续看TensorImpl这个类如何定义的\n",
    "\n",
    "Tensorimpl包含真正的数据类对象Storage以及管理storage的数据(比如sizes_, strides_, offset_, numel_等)\n",
    "\n",
    "```\n",
    "struct TensorImpl {\n",
    "    public:\n",
    "        Storage storage_;  // 数据对象\n",
    "    protected:\n",
    "        at::SmallVector<int64_t,5> sizes_;\n",
    "        at::SmallVector<int64_t,5> strides_;\n",
    "        int64_t storage_offset_ = 0;\n",
    "        int64_t numel_ = 1;\n",
    "        caffe2::TypeMeta data_type_;\n",
    "\n",
    "    public:\n",
    "        virtual IntList sizes() const;\n",
    "        virtual IntList strides() const;\n",
    "        virtual int64_t dim() const;\n",
    "        virtual const Storage& storage() const; \n",
    "        virtual int64_t storage_offset() const { \n",
    "            return storage_offset_;\n",
    "        } \n",
    "        virtual int64_t numel() const {\n",
    "                return numel_;\n",
    "        }\n",
    "       virtual bool is_contiguous() const {\n",
    "            return is_contiguous_; \n",
    "        }\n",
    "        inline void* data() const {\n",
    "            return static_cast<void*>(\n",
    "                static_cast<char*>(storage_.data()) +\n",
    "                data_type_.itemsize() * storage_offset_);\n",
    "        }\n",
    "        size_t itemsize() const {\n",
    "            AT_ASSERT(dtype_initialized());\n",
    "            return data_type_.itemsize();\n",
    "        }\n",
    "        …\n",
    "};\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们继续探究Storage的类定义, Storage实际上也是指针类型，指向底层数据类StorageImpl\n",
    "\n",
    "```\n",
    "struct Storage {\n",
    "    protected:\n",
    "        shared_ptr<StorageImpl> storage_impl_; \n",
    "    public:\n",
    "        template <typename T> T* data() const {\n",
    "            return storage_impl_->data<T>(); \n",
    "        }\n",
    "        ptrdiff_t size() const {    \n",
    "            return storage_impl_->numel();\n",
    "        }\n",
    "        int64_t numel() const {\n",
    "            return storage_impl_->numel();\n",
    "        }\n",
    "        void* data() const {\n",
    "            return storage_impl_.get()->data();\n",
    "        }\n",
    "        …\n",
    "};\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StorageImpl类定义 \n",
    "```\n",
    "struct StorageImpl {\n",
    "    private:\n",
    "        caffe2::TypeMeta data_type_; \n",
    "        DataPtr data_ptr_;       // 数据指针\n",
    "        int64_t numel_; \n",
    "        bool resizable_; \n",
    "        Allocator* allocator_;  // 内存分配器\n",
    "    public:     \n",
    "    template <typename T> inline T* data() const {\n",
    "        auto data_type_T = at::scalarTypeToDataType(c10::CTypeToScalarType<T>::to()); \n",
    "        return unsafe_data<T>(); \n",
    "    } \n",
    "    int64_t numel() const { \n",
    "        return numel_; \n",
    "    }; \n",
    "    at::DataPtr& data_ptr() { \n",
    "        return data_ptr_; \n",
    "    }; \n",
    "    void* data() const { \n",
    "        return data_ptr_.get(); \n",
    "    } \n",
    "    const at::Allocator* allocator() const { \n",
    "        return allocator_; \n",
    "    }\n",
    "    ...\n",
    "};\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，不论Tensor的维度是多少，数据本质上就是一块内存区域(未必是一块连续内存)\n",
    "\n",
    "那么Tensor是如何管理这块内存区域呢？如何检索数据？data[0][1][2]如何检索数据的?\n",
    "\n",
    "接着看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.arange(24, dtype=torch.float32).view(2, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]],\n",
       "\n",
       "        [[12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.],\n",
       "         [20., 21., 22., 23.]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 维度个数\n",
    "print(data.ndimension())\n",
    "data.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size\n",
    "data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 4, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# strides\n",
    "\n",
    "data.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/basicv8vc/pytorch-tutorials/blob/master/imgs/storage.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对数据进行检索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/basicv8vc/pytorch-tutorials/blob/master/imgs/how_to_index.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(22.)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对Tensor进行检索\n",
    "data[1][2][2] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data[1][2][2]为啥是22 ?\n",
    "\n",
    "\n",
    "由于底层数据是一维数组, 在进行检索时, 首先要做的就是确定下标值, 如何根据data[i][j][k]的i、j、k计算下标值呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data.stride()记录了每个维度的元素个数: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.]]), 12, 12)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0], data[0].numel(), data.stride(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]), 4, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][0], data[0][0].numel(), data.stride(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据data.stride()，就可以计算下标值了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/basicv8vc/pytorch-tutorials/blob/master/imgs/compute_index.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大多数情况下Tensor的数据都在一块连续内存中，但也可能有例外:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.,  5.,  7.],\n",
       "        [ 8., 10., 12.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor().set_(data.storage(), storage_offset=3, size=torch.Size([2,3]), stride=(5,2))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
